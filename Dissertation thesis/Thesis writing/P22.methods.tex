

\subsection{Methods}\label{sec:p2methods}
% reformat the subsection section since it was changed in the appendix part of paper 1
\renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Bayesian Linear Quantile Mixed Model}\label{sec:p2BLQMM}
Let $Y_{i}(t_{ij})$ be the longitudinal outcome for subject $i$ measured at time $t_{ij}$ where $i=1, \cdots, N\mbox{ and } j=1,\cdots, n_i$. Consider the linear mixed effects model:
\begin{equation}\label{eqn:p2lmm}
Y_{i}(t) ={\boldsymbol X}_{i}^{\top}(t) \boldsymbol{\beta}+ {\boldsymbol Z}_{i}^{\top}(t)\boldsymbol{u}_i + \varepsilon_{i}(t),
\end{equation}

\noindent where $\boldsymbol{\beta}$ is a $p-$dimensional vector of fixed effects,  ${\boldsymbol X}_{i}(t)$ contains the corresponding fixed covariates, $\boldsymbol{u}_i$ is a $k-$dimensional vector of random effects for subject $i$, and ${\boldsymbol Z}_{i}(t)$ are the corresponding random covariates.

An LQMM assumes that the conditional quantile of the outcome is a linear function of the covariates, i.e.,
\begin{equation}\label{eqn:p2lqmm}
Q_{Y_{i}(t)|{\boldsymbol X}_{i}(t),{\boldsymbol Z}_{i}(t)}(\tau)={\boldsymbol X}_{i}^{\top}(t) \boldsymbol{\beta}+ {\boldsymbol Z}_{i}^{\top}(t)\boldsymbol{u}_i,
\end{equation}

\noindent where the $\tau$th quantile of a random variable $Y$ is defined as $Q_{Y}(\tau)=F_{Y}^{-1}(\tau)=\inf\left\{ y:F_{Y}(y)\geq\tau\right\}$, for $\tau\in [0, 1]$. Parameter estimations can then be obtained by minimizing the following loss function,

\begin{equation*}\label{eqn:p2loss_fun}
\hat{\boldsymbol{\beta}}_{\tau}=\underset{\boldsymbol{\beta}\in \mathbb{R}^{p}}{\mbox{arg min}}\sum_{i, t}\left[\rho_{\tau}\left(Y_{i}(t)-{\boldsymbol X}_{i}^{\top}(t)\boldsymbol{\beta} - {\boldsymbol Z}_{i}^{\top}(t)\boldsymbol{u}_i\right)\right],
\end{equation*}

\noindent where $\rho_{\tau}(\cdot)$ is defined as $\rho_{\tau}(Y)=Y(\tau-{I}{(Y<0)}).$

Above minimization problem can be rephrased as a maximum-likelihood problem by assuming the random error $\varepsilon_{i}(t)$ in (\ref{eqn:p2lmm}) follows ALD with location parameter equals 0, scale parameter $\sigma$ and skewness parameter $\tau$ \citep{koenker1999goodness,yu2001bayesian}:
\begin{equation*}
Y_{i}(t) ={\boldsymbol X}_{i}^{\top}(t) \boldsymbol{\beta}+ {\boldsymbol Z}_{i}^{\top}(t)\boldsymbol{u}_i + \varepsilon_{i}(t), \varepsilon_{i}(t)\sim ALD(0, \sigma, \tau).
\end{equation*}

This becomes clear when writing out the conditional likelihood function:
\begin{equation*}\label{eqn:p2ald_lqmm}
\ell(Y_{i}(t)|\boldsymbol{\beta}_{\tau},\boldsymbol{u}_i,\sigma)=\frac{\tau(1-\tau)}{\sigma}\exp\left[-\rho_{\tau}\left(\frac{Y_{i}(t)-{\boldsymbol X}_{i}^{\top}(t)\boldsymbol{\beta}_{\tau}-{\boldsymbol Z}_{i}^{\top}(t)\boldsymbol{u}_i}{\sigma}\right)\right].
\end{equation*}

In Bayesian quantile regression context a Gibbs sampler algorithm for model inference can be developed when we utilize a location-scale mixture representation of the ALD \citep{kotz2001laplace}. Under such parameterization the random error is represented as $\varepsilon_{i}(t)=\kappa_1e_{i}(t)+\kappa_2\sqrt{\sigma e_{i}(t)}v_{i}(t)$ with $v_{i}(t)\sim \mathcal{N}(0,1), e_{i}(t)\sim\exp(1/\sigma)$ and
\[\kappa_1=\frac{1-2\tau}{\tau(1-\tau)}\hspace{2em} \kappa_2^2=\frac{2}{\tau(1-\tau)}.\]


This reparameterization leads to the following linear mixed model,
\begin{equation*}\label{eqn:p2reformald2}
Y_{i}(t)={\boldsymbol X}_{i}^{\top}(t)\boldsymbol{\beta}_{\tau}+{\boldsymbol Z}_{i}^{\top}(t)\boldsymbol{u}_i+\kappa_1e_{i}(t)+\kappa_2\sqrt{\sigma e_{i}(t)}v_{i}(t),
\end{equation*}
\noindent or equivalently,
{\small
\begin{equation}\label{eqn:p2lo_sc_lh}
\ell(Y_{i}(t)|\boldsymbol{\beta}_{\tau},\boldsymbol{u}_i,e_{i}(t),\sigma)=\frac{1}{\sqrt{2\pi\kappa_2^2\sigma e_{i}(t)}}\exp\left[-\frac{(Y_{i}(t)-{\boldsymbol X}_{i}^{\top}(t)\boldsymbol{\beta}_{\tau}-{\boldsymbol Z}_{i}^{\top}(t)\boldsymbol{u}_i-\kappa_1e_{i}(t))^2}{2\kappa_2^2\sigma e_{i}(t)}\right].
\end{equation}
}

As discussed in \cite{yu2001bayesian}, irrespective of the actual distribution of the data, Bayesian quantile regression using ALD distribution works quite well for different error distributions and the performance is quite robust and satisfactory.

% Notice that Equation (\ref{eqn:p2lo_sc_lh}) actually takes the form of a normal distribution thus it is possible to implement the sampling algorithm directly in some Bayesian inference software like \textsf{BUGS}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Joint Models Using Longitudinal Quantile Regression}
% We then extend the linear model JM (LMJM), by replacing the LMM with an LQMM for the longitudinal process.
% For subject $i$, let $T_i^*$ and $T_{ik}^*$ be the underlying true death time and true $k$th recurrent event time respectively and $C_i$ be the censoring time. Assume death time is uninformative, i.e., independent of censoring time and the longitudinal process, then $T_i = \mbox{ min}(C_i, T_i^*)$ is the observed censoring time and $T_{ik} = $\mbox{ min}($T_i, T_{ik}^*)$, for $k=1, \cdots, m_i$, is the observed $k$th event time, where $m_i$ is the total number of recurrent events for subject $i$. Let $\Delta_{ik}$ be the recurrent event indicator at time $T_{ik}$ which is defined as $\Delta_{ik} = I(T_{ik}^* < T_i)$, and $I(\cdot)$ is the indicator function. A $k$th recurrent event is observed at time $T_{ik}$ if $\Delta_{ik}=1$, i.e. $T_{ik}^* < T_i$; other wise, $\Delta_{ik}=0$.

For subject $i$, let $T_{ik}^*$ be the underlying true $k$th recurrent event time and $C_i$ be the censoring time, which is assumed to be independent of both outcomes. Then $T_{ik} = $\mbox{ min}($C_i, T_{ik}^*)$, for $k=1, \cdots, m_i$, is the observed $k$th event time, where $m_i$ is the total number of recurrent events for subject $i$. Let $\Delta_{ik}$ be the recurrent event indicator at time $T_{ik}$ which is defined as $\Delta_{ik} = I(T_{ik}^* < C_i)$, and $I(\cdot)$ is the indicator function. A $k$th recurrent event is observed at time $T_{ik}$ if $\Delta_{ik}=1$, i.e. $T_{ik}^* < C_i$; other wise, $\Delta_{ik}=0$.

Let $Y_{i}(t)$ be the continuous longitudinal outcome for subject $i$ measured at time $t$. Note that we can only observe $Y_{i}(t)$ when $t\le C_i$, and the complete longitudinal trajectory up to follow-up time $t$ for subject $i$ can be written as $\mathcal{Y}_{i}(t)=\{Y_{i}(s): 0\le s\le t\}$. We denote the true underlying longitudinal measurement with $m_{i}(t)$ and his/her complete history of true longitudinal process as $\mathcal{M}_{i}(t)=\{m_{i}(s): 0\le s \le t\}$. We propose a new JM that uses longitudinal quantile mixed model (LQMM) as follows:
\begin{equation}\label{eqn:p2joint}
\left\{
\begin{array}{l}
Y_{i}(t) = m_{i}(t) + \varepsilon_{i}(t) = {\boldsymbol X}_{i}^{\top}(t)\boldsymbol{\beta}_{\tau} + {\boldsymbol Z}_{i}^{\top}(t){\boldsymbol u}_i + \varepsilon_{i}(t), \varepsilon_{i}(t)\sim ALD(0, \sigma, \tau)\\
r_i(t|\mathcal{M}_{i}(t), {\boldsymbol W}_i;  \boldsymbol{\gamma}_{\tau}, \alpha_{\tau}) = r_{i0}(t)\exp({\boldsymbol W}_i^{\top}\boldsymbol{\gamma}_{\tau} + \alpha_{\tau}({\boldsymbol X}^{\top}_{i}(t)\boldsymbol{\beta}_{\tau} + {\boldsymbol Z}^{\top}_{i}(t){\boldsymbol u}_{i}))
\end{array}
\right.
\end{equation}

\noindent where in the LQMM for the longitudinal process, $\boldsymbol{X}_{i}(t)$ are $p-$dimensional fixed effect covariates and $\boldsymbol{Z}_{i}(t)$ are $k-$dimensional covariates associated with the $k-$dimensional multivariate normal random effects $\boldsymbol{u}_i$. The submodel for recurrent event process takes the format of Cox proportional hazards model (PHM) where $r_{i0}(\cdot)$ is the baseline intensity function and $\boldsymbol{W}_{i}$ are $q-$dimensional fixed effect covariates that are only associated with event time (not the longitudinal outcome). In Equation (\ref{eqn:p2joint}), individual heterogeneity is captured by ${\boldsymbol Z}_{i}^{\top}(t){\boldsymbol u}_i$, which is the deviation of subject $i$ from the population average. Meanwhile, these two models are linked by treating the longitudinal outcome as a time dependent covariate in the recurrent event process, and the degree of associations is measured by parameter $\alpha$.

% \subsection{The Recurrent Events Submodel}\label{sec:p2surv_submodel}
Assume a total number of $m_i$ events are observed for subject $i$ within the censoring time $C_i$. The likelihood function for recurrent event data can be written as:
{\small
\begin{eqnarray}\label{eqn:p2lik_sur}
\ell({\boldsymbol T}_i, \boldsymbol{\Delta}_i;\boldsymbol{\theta})&=& \nonumber \prod_{k=1}^{m_i}\left[r_i(T_{ik};\boldsymbol{\theta}|\mathcal{M}_{i}(T_{ik}), \boldsymbol{W}_i)^{\Delta_{ik}}\exp\left(-\int_{T_{ik-1}}^{T_{ik}}r_i(s;\boldsymbol{\theta}|\mathcal{M}_{i}(s), \boldsymbol{W}_i)ds\right)\right]\\
&=& \prod_{k=1}^{m_i}\left[r_i(T_{ik};\boldsymbol{\theta}|\mathcal{M}_{i}(T_{ik}), \boldsymbol{W}_i)^{\Delta_{ik}}\right]\exp\left(-\int_0^{T_{im_i}}r_i(s;\boldsymbol{\theta}|\mathcal{M}_{i}(s), \boldsymbol{W}_i)ds\right),
\end{eqnarray}
}
\noindent where $r_i(\cdot)$ is given in (\ref{eqn:p2joint}) and $T_{i0}$ is set to be 0.

For the baseline intensity $r_{i0}(t)$, a parametric form such as Weibull model can be used or it can be left unspecified. Specifically, we consider constant baseline intensity and piecewise-constant baseline intensity function in simulation study and data application respectively. A wider range of baseline intensity functions can also be used and the integration can be approximated with some numeric methods (e.g. Simpson's rule). Besides the Cox PHM, other functional forms can also be considered for the the recurrent events submodel. For example, accelerated failure time model when the proportionality assumption is violated and counting process approach is another nonparametric option.

In quantile regression, all parameter estimators are functions of the quantile. This is also true in the proposed JM. That is, parameter estimations in the recurrent events submodel, such as $\alpha$ and $\boldsymbol{\gamma}$, also change depending which $\tau$ is chosen. Quantile regression provides us the flexibility to conduct a study over the entire conditional distribution of the longitudinal outcome through fitting the model using a set of selected quantiles. Less varying values in the estimation indicates a relatively stable covariate effect on the outcome, and vice versa. If the interest lies only in assessing the effect on the lower or higher quantile of the longitudinal outcome and its association with the event process we may just fix the quantile and conduct the analysis. For simplicity we omit the quantile notation in all parameters in the following sections (e.g. $\boldsymbol{\theta}$ stands for $\boldsymbol{\theta}_{\tau}$ for all quantile-based parameters).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Complete Likelihood Function and Bayesian Inference}\label{sec:p2estimation}
For subject $i$, the complete joint likelihood function of the longitudinal and recurrent event data is the product of three components: the conditional likelihood functions of the longitudinal and recurrent event outcomes (conditional on the unobserved random effects) and the density of the random effects:
\begin{equation}\label{eqn:p2full_lik}
L_i(\boldsymbol{\theta};{\boldsymbol T}_i, \boldsymbol{\Delta}_i, \mathcal{Y}_{i}(C_i), \boldsymbol{u}_i) = \ell(\mathcal{Y}_{i}(C_i); \boldsymbol{\theta}|\boldsymbol{u}_i)\ell({\boldsymbol T}_i, {\boldsymbol\Delta}_i; \boldsymbol{\theta}|\boldsymbol{u}_i)f(\boldsymbol{u}_i|\boldsymbol{\Sigma}),
\end{equation}

\noindent where vector $\boldsymbol{\theta}$ represents a set of all the parameters from each distribution function in (\ref{eqn:p2full_lik}),  $\ell(\boldsymbol{T}_i, \boldsymbol{\Delta}_i; \boldsymbol{\theta}|\boldsymbol{u}_i)$ is given in (\ref{eqn:p2lik_sur}) and $\ell(\mathcal{Y}_{i}(C_i); \boldsymbol{\theta}|\boldsymbol{u}_i)=\prod_{0\le t\le C_i}\ell(Y_{i}(t); \boldsymbol{\theta}|\boldsymbol{u}_i)$, where $\ell(Y_{i}(t), \boldsymbol{\theta}|\boldsymbol{u}_i)$ takes the format of (\ref{eqn:p2lo_sc_lh}), and random effects are assumed to be multivariate normal.

For parameter estimation, we take advantage of the location-scale mixture representation of the ALD that is described in Section \ref{sec:p2BLQMM} and propose a fully Bayesian inference approach for unknown parameters. Specifically, given the complete likelihood function in (\ref{eqn:p2full_lik}) and according to the Bayes theorem, the posterior distributions of the model parameters is given by
\begin{equation}\label{eqn:p2posterior}
f(\boldsymbol{\theta}|\boldsymbol{T}, \boldsymbol{\Delta}, \bm{\mathcal{Y}}, \boldsymbol{u})\propto \prod_{i=1}^N L_i(\boldsymbol{T}_i, \boldsymbol{\Delta}_i, \mathcal{Y}_{i}(C_i), \boldsymbol{u}_i;\boldsymbol{\theta}) f(\boldsymbol{\theta}),
\end{equation}

\noindent where $N$ is the total number subjects, $\boldsymbol{T}=(\boldsymbol{T}_1, \boldsymbol{T}_2, \cdots, \boldsymbol{T}_N)$, $\bm{\mathcal{Y}}=(\mathcal{Y}_{1}(C_1), \mathcal{Y}_{2}(C_2), \cdots, \mathcal{Y}_{N}(C_N))$, $\boldsymbol{\Delta} =(\boldsymbol{\Delta}_1, \boldsymbol{\Delta}_2, \cdots, \boldsymbol{\Delta}_N)$, $\boldsymbol{u}=(\boldsymbol{u}_1, \boldsymbol{u}_2, \cdots, \boldsymbol{u}_N)$, and $f(\boldsymbol{\theta})$ is the product of the prior distributions:
\[f(\boldsymbol{\theta})=\pi(\boldsymbol{\beta})\pi(\boldsymbol{\gamma})\pi(\alpha)\pi(\sigma)\pi(\boldsymbol{\Sigma}),\]

\noindent where $\boldsymbol{\Sigma}$ is a $k\times k$ covariance matrix of the random effects. We may choose the following prior distributions:
$\boldsymbol{\beta} \sim \mathcal{N}_p({\boldsymbol 0}, 10^3{\bf I}), \boldsymbol{\gamma} \sim \mathcal{N}_q({\boldsymbol 0}, 10^3{\bf I}), \alpha\sim \mathcal{N}(0, 10^3), \sigma\sim \mathcal{IG}(10^{-3}, 10^{-3}), \boldsymbol{\Sigma}^{-1}\sim Wishart({\bf I}, k+1). $
We also consider Cholesky decomposition prior for $\boldsymbol{\Sigma}$ in our simulation studies and find similar results as Wishart prior gives (results not shown). In the simulation study, we find that the posterior inference is not sensitive to the prior choice.

By using fully Bayesian approach the uncertainty of the parameter estimates is fully captured in the posterior distributions and no asymptotic theory is needed to derive the standard error. It is straightforward to code the proposed JM and implement it in \textsf{JAGS} software \citep{plummer2003jags} and the \textsf{JAGS} model file for simulation study is provided separately in Web Supplement.









%All is done in \LaTeX \cite{knuth1986texbook}.
%
%
% \bibliographystyle{plainnat}%%%%%%%%%%%%%%%%%%%%
% \addcontentsline{toc}{section}{References}
% \bibliography{QRJM}


% \end{document}